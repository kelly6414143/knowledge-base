# å»ºç½®æœ¬åœ° LLM(Winodws+nodeJS)

<details>
<summary>æç¤ºè©</summary>
å¾ŒçºŒå†å¢åŠ 
</details>

## æ¶æ§‹

```=arduino
Ollamaï¼ˆæœ¬åœ°æ¨è«–ï¼‰
     â†‘  â†“  localhost:11434
Node.js RAG Server
     â”œâ”€ ingestï¼šæ–‡ä»¶ & Axure HTML â†’ åˆ‡chunk â†’ Embedding
     â”œâ”€ vectorDBï¼šChromaï¼ˆNodeç‰ˆæœ¬ï¼‰å­˜å‘é‡
     â”œâ”€ askï¼šæœå°‹ç‰‡æ®µ + Prompt + LLM å›ç­”
React å‰ç«¯ï¼ˆå¯é¸ï¼‰

```

## åµæ¸¬é›»è…¦æ˜¯å¦èƒ½è·‘[7B / 8B]æ¨¡å‹

æä¾›è³‡è¨Šå¦‚ä¸‹

```=yaml
CPUï¼šIntel i7-12700H
GPUï¼šNVIDIA RTX 3050 4GB
RAMï¼š16GB
ä½œæ¥­ç³»çµ±ï¼šWindows 11
```

## ä¸‹è¼‰ Ollama

> Ollama æ˜¯ LLM æ¨¡å‹ç®¡ç†å·¥å…·  
> å°±æ˜¯ä¸€å€‹è®“ä½ è¼•é¬†ä¸‹è¼‰ã€å•Ÿå‹•ã€ç®¡ç† AI æ¨¡å‹çš„å·¥å…·ã€‚

åˆ°å®˜ç¶²ï¼šhttps://ollama.com/download

> æ³¨æ„
>
> - å®‰è£å¾Œ Ollama æœƒè‡ªå‹•å•Ÿå‹•
> - ç³»çµ±æ‰˜ç›¤ï¼ˆå³ä¸‹è§’ï¼‰æœƒçœ‹åˆ° Ollama å°åœ–ç¤º
> - ä¸éœ€è¦ä½ ç™»å…¥ä»»ä½•å¸³è™Ÿã€ä¸éœ€è¦ API key

å®‰è£å¾Œåœ¨ PowerShell è¼¸å…¥ï¼š

```
ollama --version
```

## æœ¬åœ° LLM å»ºç½®

### ä¸‹è¼‰ä¸¦é‹è¡Œæ¨¡å‹ï¼ˆé¦–æ¬¡æ¸¬è©¦ï¼‰

1. é–‹å•Ÿ PowerShell (ç³»çµ±ç®¡ç†å“¡èº«åˆ†)
2. è¼¸å…¥æŒ‡ä»¤ä¸‹è¼‰æ¨¡å‹ (ä»¥ Qwen2.5 7B ç‚ºä¾‹)

   ```
   ollama run qwen2.5:7b
   ```

   ä½ æœƒçœ‹åˆ°ç•«é¢åƒé€™æ¨£ï¼š

   ```
   pulling qwen2.5:7b...
   ...
   >>
   ```

3. æ¸¬è©¦æ¨¡å‹æ˜¯å¦æ­£å¸¸

   ä¸‹è¼‰å®Œæˆå¾Œï¼Œåœ¨ `>>` å¾Œé¢è¼¸å…¥ï¼š `ä½ å¥½`

   å¦‚æœä½ çœ‹åˆ° AI å›è¦†ï¼Œä»£è¡¨ï¼šæœ¬åœ° LLM å»ºç½®æˆåŠŸ ğŸ‰

### æ¸¬è©¦ Ollama çš„æœ¬åœ° API

> Ollama å…§å»ºä¸€å€‹ HTTP APIï¼š  
> `http://localhost:11434`

1. åœ¨ PowerShell è¼¸å…¥ä»¥ä¸‹æŒ‡ä»¤

```=powershell
Invoke-WebRequest `
-Uri "http://localhost:11434/api/generate" `
-Method POST `
-ContentType "application/json" `
-Body '{"model":"qwen2.5:7b","prompt":"API æ¸¬è©¦"}'
```

åŸ·è¡Œå¾Œä½ æœƒçœ‹åˆ°åƒé€™æ¨£çš„ JSON è¼¸å‡ºï¼Œä»£è¡¨ï¼šLLM API å·²ç¶“æˆåŠŸé‹ä½œï¼ğŸ‰

```=arduino
{"model":"qwen2.5:7b","created_at":...,"response":"...."}
```

> PS: å¯ä½¿ç”¨ **postman** å»é©—è­‰

### ä½¿ç”¨ Node.js å‘¼å«æœ¬åœ° LLM

1. æ–°å¢ä¸€å€‹è³‡æ–™å¤¾  
   `local-llm-test`
2. åˆå§‹åŒ– Node å°ˆæ¡ˆ  
   `npm init-y`
3. å®‰è£ axios  
   `npm install axios`
4. å»ºç«‹ç¬¬ä¸€æ”¯ Node.js LLM å‘¼å«ç¨‹å¼
   - å»ºç«‹æª”æ¡ˆ `test-llm.js`ï¼Œå…§å®¹å¯ä»¥çœ‹ä»£ç¢¼
   - åŸ·è¡Œ `node test-llm.js`

### æœ¬åœ° LLM API Server

1. æª”æ¡ˆ `package.json` æ·»åŠ ï¼Œ`"type": "module"`
2. å®‰è£ `Express + CORS`
   ```=bash
   npm install express cors axios
   ```
3. å»ºç«‹ `server.js`ï¼Œå…§å®¹å¯ä»¥çœ‹ä»£ç¢¼
   - å•Ÿå‹•æœ¬åœ° API Serverï¼š`node server.js`

### å¾ŒçºŒçš„/chat ç›¸é—œ APIï¼Œéƒ½å¯ä»¥åœ¨ postman æ¸¬è©¦ï¼Œä»¥åŠå¢åŠ å‰ç«¯ç•«é¢

## åœ¨ Ollama è£ embedding æ¨¡å‹

```
ollama pull nomic-embed-text
```

> å¾ Ollama å®˜æ–¹åº«ä¸‹è¼‰ nomic-embed-text  
> é€™æ˜¯ä¸€é¡†å°ˆé–€ç”¨ä¾†åšå‘é‡åµŒå…¥ï¼ˆembeddingsï¼‰çš„æ¨¡å‹  
> ä¸‹è¼‰å®Œæˆå¾Œï¼Œ/api/embeddings å°±å¯ä»¥ç”¨å®ƒä¾†ç®—å‘é‡

ç¢ºèªæ˜¯å¦å­˜åœ¨

```
ollama list
```

---

### å…¶ä»–

#### æ•´é«”æ¶æ§‹ï¼ˆWindows + Node.jsï¼‰

```
Ollamaï¼ˆæœ¬åœ°æ¨è«–ï¼‰
     â†‘  â†“  localhost:11434
Node.js RAG Server
     â”œâ”€ ingestï¼šæ–‡ä»¶ & Axure HTML â†’ åˆ‡chunk â†’ Embedding
     â”œâ”€ vectorDBï¼šChromaï¼ˆNodeç‰ˆæœ¬ï¼‰å­˜å‘é‡
     â”œâ”€ askï¼šæœå°‹ç‰‡æ®µ + Prompt + LLM å›ç­”
React å‰ç«¯ï¼ˆå¯é¸ï¼‰

```

#### å°ˆæ¡ˆçµæ§‹ï¼ˆNode.js ç‰ˆï¼‰

```
company-rag-node/
â”œâ”€ data/
â”‚  â”œâ”€ docs/               # å…¬å¸æ–‡ä»¶ txt/md/pdfï¼ˆå…ˆæ”¯æŒ txt/mdï¼‰
â”‚  â””â”€ prototypes/         # Axure HTML åŸå‹ï¼ˆ*.htmlï¼‰
â”œâ”€ src/
â”‚  â”œâ”€ ingest.ts           # å»ºç´¢å¼•
â”‚  â”œâ”€ query.ts            # æŸ¥è©¢ & Prompt
â”‚  â”œâ”€ htmlParser.ts       # è§£æ Axure HTML
â”‚  â”œâ”€ server.ts           # Express API /ask
â”‚  â”œâ”€ vector.ts           # Chroma Clientï¼ˆNode ç‰ˆï¼‰
â”‚  â””â”€ config.ts
â”œâ”€ package.json
â””â”€ tsconfig.json

```
